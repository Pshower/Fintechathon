{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef6d5819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# save activations derivatives\n",
    "# implement backpropagation\n",
    "# implement gradient descent\n",
    "# implement train\n",
    "# train our net with some dummy dataset\n",
    "# make some predictions\n",
    "\n",
    "class MLP:\n",
    "    \n",
    "    def __init__(self, num_inputs = 3, num_hidden = [3, 5], num_outputs = 2):\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_hidden = num_hidden\n",
    "        self.num_outputs = num_outputs\n",
    "        \n",
    "        layers = [self.num_inputs] + self.num_hidden + [self.num_outputs]\n",
    "        \n",
    "        # initiate random weights\n",
    "        self.weights = []\n",
    "        for i in range(len(layers) - 1):\n",
    "            w = np.random.rand(layers[i], layers[i + 1])\n",
    "            self.weights.append(w)\n",
    "            \n",
    "        self.activations = []\n",
    "        for i in range(len(layers)):\n",
    "            a = np.zeros(layers[i])\n",
    "            self.activations.append(a)\n",
    "            \n",
    "        self.derivatives = []\n",
    "        for i in range(len(layers) - 1):\n",
    "            a = np.zeros((layers[i], layers[i + 1]))\n",
    "            self.derivatives.append(a)\n",
    "        \n",
    "    def forward_propagate(self, inputs):\n",
    "        # first layers\n",
    "        activations = inputs\n",
    "        self.activations[0] = inputs\n",
    "        \n",
    "        for i, w in enumerate(self.weights):\n",
    "            # calculate net inpus\n",
    "            net_inputs = np.dot(activations, w)\n",
    "            \n",
    "            # calculate the activations\n",
    "            activations = self._sigmoid(net_inputs)\n",
    "            self.activations[i + 1] = activations\n",
    "        \n",
    "        # a_3 = s(h_3)\n",
    "        # h_3 = a_2 * W_2\n",
    "            \n",
    "        return activations\n",
    "    \n",
    "    def back_propagate(self, error, verbose = False):\n",
    "        \n",
    "        # dE/dW_i = (y - a_[i+1]) s'(h_[i+1]) a_i\n",
    "        # s'(h_[i+1]) = s(h_[i+1])(1 - s(h_[i+1]))\n",
    "        # s(h_[i+1]) = a_[i+1]\n",
    "        \n",
    "        # dE/dW_[i-1] = (y - a_[i+1]) s'(h_[i+1]) W_i s'(h_i) a_[i-1]\n",
    "        \n",
    "        for i in reversed(range(len(self.derivatives))):\n",
    "            activations = self.activations[i + 1]\n",
    "            delta = error * self._sigmoid_derivative(activations)\n",
    "            delta_reshaped = delta.reshape(delta.shape[0], -1).T\n",
    "            current_activations = self.activations[i]\n",
    "            current_activations_reshaped = current_activations.reshape(current_activations.shape[0], -1)\n",
    "            \n",
    "            self.derivatives[i] = np.dot(current_activations_reshaped, delta_reshaped)\n",
    "            \n",
    "            error = np.dot(delta, self.weights[i].T)\n",
    "            \n",
    "            if verbose:\n",
    "                print(\"Derivatives for W{}:\\n{}\".format(i, self.derivatives[i]))\n",
    "        \n",
    "        return error\n",
    "    \n",
    "    def gradient_descent(self, learning_rate, verbose = False):\n",
    "        for i in range(len(self.weights)):\n",
    "            weights = self.weights[i]\n",
    "            if verbose:\n",
    "                print(\"Original W{}:\\n{}\".format(i, weights))\n",
    "            derivatives = self.derivatives[i]\n",
    "            weights += derivatives * learning_rate\n",
    "            if verbose:\n",
    "                print(\"Updated W{}:\\n{}\".format(i, weights))\n",
    "                \n",
    "    def train(self, inputs, targets, epochs, learning_rate, verbose = False):\n",
    "        for i in range(epochs):\n",
    "            sum_error = 0\n",
    "            for (inp, tar) in zip(inputs, targets):\n",
    "                \n",
    "                # forward propagation\n",
    "                outputs = self.forward_propagate(inp)\n",
    "\n",
    "                # calculate error\n",
    "                error = tar - outputs\n",
    "\n",
    "                # back propagation\n",
    "                self.back_propagate(error)\n",
    "\n",
    "                # apply gradient descent\n",
    "                self.gradient_descent(learning_rate)\n",
    "                \n",
    "                # caculate accumulative error\n",
    "                sum_error += self._mse(tar, outputs)\n",
    "                \n",
    "            # report error\n",
    "            if verbose:\n",
    "                print(\"Error: {} at epoch {}\".format(sum_error / len(inputs), i))\n",
    "                \n",
    "            \n",
    "    def _sigmoid(self, x):\n",
    "        return 1.0 / (1 + np.exp(-x))\n",
    "    \n",
    "    def _sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def _mse(self, target, outputs):\n",
    "        return np.average((target - outputs)**2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1072097",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Derivatives for W2:\n",
      "[[-0.07102142]\n",
      " [-0.06999514]\n",
      " [-0.05377381]\n",
      " [-0.06346849]\n",
      " [-0.06927592]]\n",
      "Derivatives for W1:\n",
      "[[-0.00142864 -0.0008026  -0.00409886 -0.00581119 -0.00045723]\n",
      " [-0.00147105 -0.00082643 -0.00422052 -0.00598368 -0.00047081]\n",
      " [-0.0014674  -0.00082438 -0.00421005 -0.00596884 -0.00046964]\n",
      " [-0.0014267  -0.00080151 -0.00409329 -0.0058033  -0.00045661]\n",
      " [-0.00143396 -0.00080559 -0.00411412 -0.00583283 -0.00045894]]\n",
      "Derivatives for W0:\n",
      "[[-3.64774517e-04 -9.24329540e-05 -1.30066940e-04 -2.32659677e-04\n",
      "  -4.31600919e-04]\n",
      " [-7.29549034e-04 -1.84865908e-04 -2.60133880e-04 -4.65319354e-04\n",
      "  -8.63201839e-04]]\n",
      "Original W0:\n",
      "[[0.14557939 0.77749819 0.49347512 0.11932386 0.45712787]\n",
      " [0.67032956 0.67585158 0.7901218  0.6687976  0.55478191]]\n",
      "Updated W0:\n",
      "[[0.14557574 0.77749726 0.49347382 0.11932153 0.45712356]\n",
      " [0.67032226 0.67584973 0.7901192  0.66879295 0.55477327]]\n",
      "Original W1:\n",
      "[[0.63985565 0.89933603 0.13699123 0.95240083 0.32361689]\n",
      " [0.63914487 0.14776707 0.08376032 0.06293039 0.58536139]\n",
      " [0.98930092 0.53189132 0.02463191 0.08241263 0.88425616]\n",
      " [0.73411603 0.82851413 0.41227786 0.23431464 0.56786438]\n",
      " [0.4206749  0.84820042 0.53518157 0.94874531 0.7448768 ]]\n",
      "Updated W1:\n",
      "[[0.63984136 0.89932801 0.13695024 0.95234272 0.32361232]\n",
      " [0.63913016 0.1477588  0.08371811 0.06287055 0.58535669]\n",
      " [0.98928625 0.53188308 0.02458981 0.08235294 0.88425146]\n",
      " [0.73410176 0.82850611 0.41223693 0.23425661 0.56785981]\n",
      " [0.42066056 0.84819237 0.53514043 0.94868698 0.74487221]]\n",
      "Original W2:\n",
      "[[0.2788644 ]\n",
      " [0.14541702]\n",
      " [0.41191386]\n",
      " [0.75308262]\n",
      " [0.07898609]]\n",
      "Updated W2:\n",
      "[[0.27815418]\n",
      " [0.14471707]\n",
      " [0.41137612]\n",
      " [0.75244793]\n",
      " [0.07829333]]\n",
      "Original W0:\n",
      "[[0.14557574 0.77749726 0.49347382 0.11932153 0.45712356]\n",
      " [0.67032226 0.67584973 0.7901192  0.66879295 0.55477327]]\n",
      "Updated W0:\n",
      "[[0.1455721  0.77749634 0.49347252 0.11931921 0.45711924]\n",
      " [0.67031497 0.67584789 0.7901166  0.66878829 0.55476464]]\n",
      "Original W1:\n",
      "[[0.63984136 0.89932801 0.13695024 0.95234272 0.32361232]\n",
      " [0.63913016 0.1477588  0.08371811 0.06287055 0.58535669]\n",
      " [0.98928625 0.53188308 0.02458981 0.08235294 0.88425146]\n",
      " [0.73410176 0.82850611 0.41223693 0.23425661 0.56785981]\n",
      " [0.42066056 0.84819237 0.53514043 0.94868698 0.74487221]]\n",
      "Updated W1:\n",
      "[[0.63982708 0.89931998 0.13690926 0.9522846  0.32360775]\n",
      " [0.63911545 0.14775054 0.08367591 0.06281072 0.58535198]\n",
      " [0.98927157 0.53187484 0.02454771 0.08229325 0.88424676]\n",
      " [0.73408749 0.8284981  0.412196   0.23419858 0.56785525]\n",
      " [0.42064622 0.84818431 0.53509929 0.94862865 0.74486762]]\n",
      "Original W2:\n",
      "[[0.27815418]\n",
      " [0.14471707]\n",
      " [0.41137612]\n",
      " [0.75244793]\n",
      " [0.07829333]]\n",
      "Updated W2:\n",
      "[[0.27744397]\n",
      " [0.14401711]\n",
      " [0.41083838]\n",
      " [0.75181325]\n",
      " [0.07760057]]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # create an mlp\n",
    "    mlp = MLP(2, [5, 5], 1)\n",
    "    \n",
    "    # create dummy data\n",
    "    inputs = np.array([.1, .2])\n",
    "    target = np.array([.3])\n",
    "    \n",
    "    # forward propagation\n",
    "    outputs = mlp.forward_propagate(inputs)\n",
    "    \n",
    "    # calculate error\n",
    "    error = target - outputs\n",
    "    \n",
    "    # back propagation\n",
    "    mlp.back_propagate(error, True)\n",
    "    \n",
    "    # apply gradient descent\n",
    "    mlp.gradient_descent(0.01, True)\n",
    "    mlp.gradient_descent(0.01, True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09d6b8f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.04475841543317108 at epoch 0\n",
      "Error: 0.04137272418394314 at epoch 1\n",
      "Error: 0.04119058499695978 at epoch 2\n",
      "Error: 0.04099579309724114 at epoch 3\n",
      "Error: 0.04078639880488115 at epoch 4\n",
      "Error: 0.040558502017975756 at epoch 5\n",
      "Error: 0.040307956021318 at epoch 6\n",
      "Error: 0.04003032883886175 at epoch 7\n",
      "Error: 0.03972086716263121 at epoch 8\n",
      "Error: 0.039374474682704656 at epoch 9\n",
      "Error: 0.0389857107763632 at epoch 10\n",
      "Error: 0.03854881738771088 at epoch 11\n",
      "Error: 0.03805778383951942 at epoch 12\n",
      "Error: 0.03750646086643285 at epoch 13\n",
      "Error: 0.03688873572558739 at epoch 14\n",
      "Error: 0.03619877892741834 at epoch 15\n",
      "Error: 0.0354313688073423 at epoch 16\n",
      "Error: 0.034582291692862185 at epoch 17\n",
      "Error: 0.03364880213500321 at epoch 18\n",
      "Error: 0.03263011006494885 at epoch 19\n",
      "Error: 0.03152784225992672 at epoch 20\n",
      "Error: 0.03034640899023686 at epoch 21\n",
      "Error: 0.029093199829667602 at epoch 22\n",
      "Error: 0.027778541832955323 at epoch 23\n",
      "Error: 0.026415381766478306 at epoch 24\n",
      "Error: 0.02501869865001361 at epoch 25\n",
      "Error: 0.02360470328581472 at epoch 26\n",
      "Error: 0.0221899232690047 at epoch 27\n",
      "Error: 0.020790292273529257 at epoch 28\n",
      "Error: 0.01942035547168042 at epoch 29\n",
      "Error: 0.01809267255648911 at epoch 30\n",
      "Error: 0.01681745698867306 at epoch 31\n",
      "Error: 0.015602447752179113 at epoch 32\n",
      "Error: 0.014452977973562521 at epoch 33\n",
      "Error: 0.0133721875548593 at epoch 34\n",
      "Error: 0.012361323598262796 at epoch 35\n",
      "Error: 0.011420078875627173 at epoch 36\n",
      "Error: 0.01054693014881401 at epoch 37\n",
      "Error: 0.009739450813223617 at epoch 38\n",
      "Error: 0.008994583587164501 at epoch 39\n",
      "Error: 0.008308867646025205 at epoch 40\n",
      "Error: 0.007678620525414505 at epoch 41\n",
      "Error: 0.007100078660484508 at epoch 42\n",
      "Error: 0.006569502166599968 at epoch 43\n",
      "Error: 0.006083249976961927 at epoch 44\n",
      "Error: 0.005637831214972297 at epoch 45\n",
      "Error: 0.005229938046025759 at epoch 46\n",
      "Error: 0.004856464461435881 at epoch 47\n",
      "Error: 0.004514514640613045 at epoch 48\n",
      "Error: 0.004201403794950606 at epoch 49\n",
      "Error: 0.003914653753505823 at epoch 50\n",
      "Error: 0.003651985015660777 at epoch 51\n",
      "Error: 0.0034113065642724636 at epoch 52\n",
      "Error: 0.003190704392262873 at epoch 53\n",
      "Error: 0.0029884294317489065 at epoch 54\n",
      "Error: 0.0028028853734529255 at epoch 55\n",
      "Error: 0.0026326167125000723 at epoch 56\n",
      "Error: 0.0024762972439232806 at epoch 57\n",
      "Error: 0.002332719148340397 at epoch 58\n",
      "Error: 0.002200782748199159 at epoch 59\n",
      "Error: 0.0020794869720970857 at epoch 60\n",
      "Error: 0.0019679205346302296 at epoch 61\n",
      "Error: 0.0018652538186822902 at epoch 62\n",
      "Error: 0.0017707314335053848 at epoch 63\n",
      "Error: 0.0016836654134656471 at epoch 64\n",
      "Error: 0.001603429017502344 at epoch 65\n",
      "Error: 0.0015294510871200603 at epoch 66\n",
      "Error: 0.0014612109203136743 at epoch 67\n",
      "Error: 0.0013982336196369373 at epoch 68\n",
      "Error: 0.0013400858742481192 at epoch 69\n",
      "Error: 0.001286372137891593 at epoch 70\n",
      "Error: 0.0012367311671864524 at epoch 71\n",
      "Error: 0.0011908328871337271 at epoch 72\n",
      "Error: 0.00114837555331703 at epoch 73\n",
      "Error: 0.001109083182782237 at epoch 74\n",
      "Error: 0.0010727032279927566 at epoch 75\n",
      "Error: 0.0010390044705377956 at epoch 76\n",
      "Error: 0.0010077751134048513 at epoch 77\n",
      "Error: 0.000978821052607327 at epoch 78\n",
      "Error: 0.0009519643107822392 at epoch 79\n",
      "Error: 0.0009270416170448135 at epoch 80\n",
      "Error: 0.0009039031189128926 at epoch 81\n",
      "Error: 0.000882411213502239 at epoch 82\n",
      "Error: 0.0008624394864529228 at epoch 83\n",
      "Error: 0.0008438717481870139 at epoch 84\n",
      "Error: 0.0008266011581274622 at epoch 85\n",
      "Error: 0.0008105294284373449 at epoch 86\n",
      "Error: 0.0007955660996760549 at epoch 87\n",
      "Error: 0.0007816278815230821 at epoch 88\n",
      "Error: 0.0007686380523985207 at epoch 89\n",
      "Error: 0.0007565259124197688 at epoch 90\n",
      "Error: 0.0007452262846824356 at epoch 91\n",
      "Error: 0.0007346790603467245 at epoch 92\n",
      "Error: 0.0007248287834538067 at epoch 93\n",
      "Error: 0.00071562427179501 at epoch 94\n",
      "Error: 0.0007070182705148022 at epoch 95\n",
      "Error: 0.0006989671354503351 at epoch 96\n",
      "Error: 0.0006914305434998131 at epoch 97\n",
      "Error: 0.0006843712275721169 at epoch 98\n",
      "Error: 0.0006777547339043704 at epoch 99\n",
      "Error: 0.0006715491997447509 at epoch 100\n",
      "Error: 0.0006657251495876217 at epoch 101\n",
      "Error: 0.0006602553083188009 at epoch 102\n",
      "Error: 0.0006551144297829125 at epoch 103\n",
      "Error: 0.0006502791394231913 at epoch 104\n",
      "Error: 0.0006457277897696283 at epoch 105\n",
      "Error: 0.0006414403276639735 at epoch 106\n",
      "Error: 0.0006373981722121189 at epoch 107\n",
      "Error: 0.0006335841025465231 at epoch 108\n",
      "Error: 0.0006299821545644274 at epoch 109\n",
      "Error: 0.0006265775258829227 at epoch 110\n",
      "Error: 0.0006233564883198731 at epoch 111\n",
      "Error: 0.0006203063072714565 at epoch 112\n",
      "Error: 0.0006174151674126907 at epoch 113\n",
      "Error: 0.0006146721041980205 at epoch 114\n",
      "Error: 0.000612066940684805 at epoch 115\n",
      "Error: 0.0006095902292440842 at epoch 116\n",
      "Error: 0.0006072331977608875 at epoch 117\n",
      "Error: 0.0006049876999604281 at epoch 118\n",
      "Error: 0.0006028461695278761 at epoch 119\n",
      "Error: 0.000600801577717592 at epoch 120\n",
      "Error: 0.0005988473941735036 at epoch 121\n",
      "Error: 0.0005969775507058089 at epoch 122\n",
      "Error: 0.0005951864077904369 at epoch 123\n",
      "Error: 0.0005934687235773161 at epoch 124\n",
      "Error: 0.0005918196252110818 at epoch 125\n",
      "Error: 0.000590234582284168 at epoch 126\n",
      "Error: 0.0005887093822569385 at epoch 127\n",
      "Error: 0.0005872401076930158 at epoch 128\n",
      "Error: 0.0005858231151703109 at epoch 129\n",
      "Error: 0.0005844550157394999 at epoch 130\n",
      "Error: 0.000583132656812025 at epoch 131\n",
      "Error: 0.0005818531053690955 at epoch 132\n",
      "Error: 0.0005806136323918506 at epoch 133\n",
      "Error: 0.0005794116984207 at epoch 134\n",
      "Error: 0.0005782449401591373 at epoch 135\n",
      "Error: 0.0005771111580439646 at epoch 136\n",
      "Error: 0.0005760083047099622 at epoch 137\n",
      "Error: 0.0005749344742826074 at epoch 138\n",
      "Error: 0.0005738878924376322 at epoch 139\n",
      "Error: 0.000572866907170896 at epoch 140\n",
      "Error: 0.0005718699802263672 at epoch 141\n",
      "Error: 0.0005708956791340452 at epoch 142\n",
      "Error: 0.0005699426698132807 at epoch 143\n",
      "Error: 0.0005690097097003419 at epoch 144\n",
      "Error: 0.0005680956413621743 at epoch 145\n",
      "Error: 0.0005671993865611803 at epoch 146\n",
      "Error: 0.0005663199407384521 at epoch 147\n",
      "Error: 0.0005654563678853406 at epoch 148\n",
      "Error: 0.0005646077957754807 at epoch 149\n",
      "Error: 0.0005637734115314385 at epoch 150\n",
      "Error: 0.0005629524575021123 at epoch 151\n",
      "Error: 0.0005621442274286651 at epoch 152\n",
      "Error: 0.0005613480628785473 at epoch 153\n",
      "Error: 0.000560563349928502 at epoch 154\n",
      "Error: 0.0005597895160789774 at epoch 155\n",
      "Error: 0.0005590260273835485 at epoch 156\n",
      "Error: 0.0005582723857781912 at epoch 157\n",
      "Error: 0.000557528126596332 at epoch 158\n",
      "Error: 0.0005567928162566078 at epoch 159\n",
      "Error: 0.0005560660501112182 at epoch 160\n",
      "Error: 0.0005553474504435935 at epoch 161\n",
      "Error: 0.0005546366646049746 at epoch 162\n",
      "Error: 0.0005539333632801341 at epoch 163\n",
      "Error: 0.0005532372388732878 at epoch 164\n",
      "Error: 0.0005525480040057736 at epoch 165\n",
      "Error: 0.0005518653901177504 at epoch 166\n",
      "Error: 0.0005511891461666547 at epoch 167\n",
      "Error: 0.000550519037415719 at epoch 168\n",
      "Error: 0.0005498548443062916 at epoch 169\n",
      "Error: 0.000549196361408141 at epoch 170\n",
      "Error: 0.0005485433964423604 at epoch 171\n",
      "Error: 0.0005478957693718299 at epoch 172\n",
      "Error: 0.0005472533115545835 at epoch 173\n",
      "Error: 0.0005466158649557101 at epoch 174\n",
      "Error: 0.000545983281413766 at epoch 175\n",
      "Error: 0.000545355421957934 at epoch 176\n",
      "Error: 0.0005447321561723977 at epoch 177\n",
      "Error: 0.0005441133616047331 at epoch 178\n",
      "Error: 0.0005434989232152186 at epoch 179\n",
      "Error: 0.0005428887328642909 at epoch 180\n",
      "Error: 0.0005422826888355011 at epoch 181\n",
      "Error: 0.0005416806953915065 at epoch 182\n",
      "Error: 0.0005410826623608689 at epoch 183\n",
      "Error: 0.0005404885047534912 at epoch 184\n",
      "Error: 0.0005398981424027427 at epoch 185\n",
      "Error: 0.0005393114996324437 at epoch 186\n",
      "Error: 0.0005387285049469695 at epoch 187\n",
      "Error: 0.0005381490907428984 at epoch 188\n",
      "Error: 0.0005375731930407406 at epoch 189\n",
      "Error: 0.0005370007512353107 at epoch 190\n",
      "Error: 0.000536431707863511 at epoch 191\n",
      "Error: 0.0005358660083883031 at epoch 192\n",
      "Error: 0.0005353036009977407 at epoch 193\n",
      "Error: 0.0005347444364180524 at epoch 194\n",
      "Error: 0.0005341884677397705 at epoch 195\n",
      "Error: 0.0005336356502560464 at epoch 196\n",
      "Error: 0.0005330859413122601 at epoch 197\n",
      "Error: 0.0005325393001661956 at epoch 198\n",
      "Error: 0.0005319956878580093 at epoch 199\n",
      "Error: 0.0005314550670893292 at epoch 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.0005309174021108649 at epoch 201\n",
      "Error: 0.0005303826586179156 at epoch 202\n",
      "Error: 0.0005298508036532435 at epoch 203\n",
      "Error: 0.0005293218055167873 at epoch 204\n",
      "Error: 0.0005287956336817697 at epoch 205\n",
      "Error: 0.0005282722587167033 at epoch 206\n",
      "Error: 0.0005277516522129412 at epoch 207\n",
      "Error: 0.000527233786717349 at epoch 208\n",
      "Error: 0.0005267186356697438 at epoch 209\n",
      "Error: 0.0005262061733447787 at epoch 210\n",
      "Error: 0.0005256963747979637 at epoch 211\n",
      "Error: 0.0005251892158155152 at epoch 212\n",
      "Error: 0.0005246846728677849 at epoch 213\n",
      "Error: 0.0005241827230659967 at epoch 214\n",
      "Error: 0.0005236833441220923 at epoch 215\n",
      "Error: 0.0005231865143114245 at epoch 216\n",
      "Error: 0.0005226922124381257 at epoch 217\n",
      "Error: 0.0005222004178029599 at epoch 218\n",
      "Error: 0.000521711110173471 at epoch 219\n",
      "Error: 0.0005212242697562698 at epoch 220\n",
      "Error: 0.0005207398771713219 at epoch 221\n",
      "Error: 0.0005202579134280669 at epoch 222\n",
      "Error: 0.0005197783599032642 at epoch 223\n",
      "Error: 0.0005193011983204296 at epoch 224\n",
      "Error: 0.0005188264107307453 at epoch 225\n",
      "Error: 0.0005183539794953527 at epoch 226\n",
      "Error: 0.0005178838872689156 at epoch 227\n",
      "Error: 0.0005174161169843656 at epoch 228\n",
      "Error: 0.0005169506518387464 at epoch 229\n",
      "Error: 0.000516487475280084 at epoch 230\n",
      "Error: 0.0005160265709951886 at epoch 231\n",
      "Error: 0.000515567922898354 at epoch 232\n",
      "Error: 0.0005151115151208401 at epoch 233\n",
      "Error: 0.0005146573320011429 at epoch 234\n",
      "Error: 0.000514205358075943 at epoch 235\n",
      "Error: 0.0005137555780717057 at epoch 236\n",
      "Error: 0.0005133079768968844 at epoch 237\n",
      "Error: 0.0005128625396346801 at epoch 238\n",
      "Error: 0.0005124192515363204 at epoch 239\n",
      "Error: 0.0005119780980148012 at epoch 240\n",
      "Error: 0.0005115390646390926 at epoch 241\n",
      "Error: 0.000511102137128735 at epoch 242\n",
      "Error: 0.0005106673013488235 at epoch 243\n",
      "Error: 0.000510234543305347 at epoch 244\n",
      "Error: 0.0005098038491408363 at epoch 245\n",
      "Error: 0.0005093752051303328 at epoch 246\n",
      "Error: 0.0005089485976776192 at epoch 247\n",
      "Error: 0.0005085240133117131 at epoch 248\n",
      "Error: 0.0005081014386835934 at epoch 249\n",
      "Error: 0.000507680860563158 at epoch 250\n",
      "Error: 0.0005072622658363694 at epoch 251\n",
      "Error: 0.0005068456415025959 at epoch 252\n",
      "Error: 0.0005064309746721231 at epoch 253\n",
      "Error: 0.0005060182525638264 at epoch 254\n",
      "Error: 0.0005056074625029883 at epoch 255\n",
      "Error: 0.0005051985919192562 at epoch 256\n",
      "Error: 0.0005047916283447206 at epoch 257\n",
      "Error: 0.0005043865594121143 at epoch 258\n",
      "Error: 0.0005039833728531105 at epoch 259\n",
      "Error: 0.0005035820564967264 at epoch 260\n",
      "Error: 0.0005031825982678162 at epoch 261\n",
      "Error: 0.000502784986185645 at epoch 262\n",
      "Error: 0.0005023892083625417 at epoch 263\n",
      "Error: 0.0005019952530026206 at epoch 264\n",
      "Error: 0.0005016031084005695 at epoch 265\n",
      "Error: 0.0005012127629405036 at epoch 266\n",
      "Error: 0.00050082420509486 at epoch 267\n",
      "Error: 0.0005004374234233616 at epoch 268\n",
      "Error: 0.0005000524065720094 at epoch 269\n",
      "Error: 0.0004996691432721333 at epoch 270\n",
      "Error: 0.0004992876223394769 at epoch 271\n",
      "Error: 0.0004989078326733056 at epoch 272\n",
      "Error: 0.0004985297632555792 at epoch 273\n",
      "Error: 0.0004981534031501212 at epoch 274\n",
      "Error: 0.0004977787415018363 at epoch 275\n",
      "Error: 0.0004974057675359505 at epoch 276\n",
      "Error: 0.0004970344705572724 at epoch 277\n",
      "Error: 0.000496664839949477 at epoch 278\n",
      "Error: 0.0004962968651744131 at epoch 279\n",
      "Error: 0.0004959305357714227 at epoch 280\n",
      "Error: 0.0004955658413566833 at epoch 281\n",
      "Error: 0.000495202771622563 at epoch 282\n",
      "Error: 0.0004948413163369948 at epoch 283\n",
      "Error: 0.000494481465342854 at epoch 284\n",
      "Error: 0.000494123208557361 at epoch 285\n",
      "Error: 0.0004937665359714839 at epoch 286\n",
      "Error: 0.0004934114376493585 at epoch 287\n",
      "Error: 0.0004930579037277133 at epoch 288\n",
      "Error: 0.0004927059244153115 at epoch 289\n",
      "Error: 0.0004923554899923913 at epoch 290\n",
      "Error: 0.0004920065908101193 at epoch 291\n",
      "Error: 0.0004916592172900496 at epoch 292\n",
      "Error: 0.0004913133599235959 at epoch 293\n",
      "Error: 0.0004909690092714908 at epoch 294\n",
      "Error: 0.0004906261559632799 at epoch 295\n",
      "Error: 0.0004902847906967944 at epoch 296\n",
      "Error: 0.0004899449042376434 at epoch 297\n",
      "Error: 0.0004896064874187082 at epoch 298\n",
      "Error: 0.0004892695311396404 at epoch 299\n",
      "Error: 0.000488934026366364 at epoch 300\n",
      "Error: 0.0004885999641305786 at epoch 301\n",
      "Error: 0.0004882673355292771 at epoch 302\n",
      "Error: 0.00048793613172425445 at epoch 303\n",
      "Error: 0.0004876063439416218 at epoch 304\n",
      "Error: 0.00048727796347133726 at epoch 305\n",
      "Error: 0.00048695098166672376 at epoch 306\n",
      "Error: 0.00048662538994399644 at epoch 307\n",
      "Error: 0.0004863011797817948 at epoch 308\n",
      "Error: 0.000485978342720715 at epoch 309\n",
      "Error: 0.00048565687036285476 at epoch 310\n",
      "Error: 0.0004853367543713315 at epoch 311\n",
      "Error: 0.00048501798646985407 at epoch 312\n",
      "Error: 0.00048470055844223914 at epoch 313\n",
      "Error: 0.00048438446213197866 at epoch 314\n",
      "Error: 0.0004840696894417841 at epoch 315\n",
      "Error: 0.0004837562323331347 at epoch 316\n",
      "Error: 0.00048344408282584175 at epoch 317\n",
      "Error: 0.0004831332329975994 at epoch 318\n",
      "Error: 0.0004828236749835497 at epoch 319\n",
      "Error: 0.00048251540097584485 at epoch 320\n",
      "Error: 0.000482208403223215 at epoch 321\n",
      "Error: 0.00048190267403053504 at epoch 322\n",
      "Error: 0.00048159820575839645 at epoch 323\n",
      "Error: 0.00048129499082268145 at epoch 324\n",
      "Error: 0.0004809930216941381 at epoch 325\n",
      "Error: 0.00048069229089796203 at epoch 326\n",
      "Error: 0.00048039279101337454 at epoch 327\n",
      "Error: 0.0004800945146732086 at epoch 328\n",
      "Error: 0.00047979745456350024 at epoch 329\n",
      "Error: 0.000479501603423065 at epoch 330\n",
      "Error: 0.00047920695404310567 at epoch 331\n",
      "Error: 0.0004789134992667952 at epoch 332\n",
      "Error: 0.0004786212319888788 at epoch 333\n",
      "Error: 0.00047833014515527035 at epoch 334\n",
      "Error: 0.00047804023176266006 at epoch 335\n",
      "Error: 0.00047775148485811725 at epoch 336\n",
      "Error: 0.0004774638975386891 at epoch 337\n",
      "Error: 0.0004771774629510276 at epoch 338\n",
      "Error: 0.00047689217429098825 at epoch 339\n",
      "Error: 0.0004766080248032509 at epoch 340\n",
      "Error: 0.00047632500778093653 at epoch 341\n",
      "Error: 0.00047604311656523234 at epoch 342\n",
      "Error: 0.00047576234454500626 at epoch 343\n",
      "Error: 0.0004754826851564401 at epoch 344\n",
      "Error: 0.00047520413188265466 at epoch 345\n",
      "Error: 0.0004749266782533438 at epoch 346\n",
      "Error: 0.000474650317844403 at epoch 347\n",
      "Error: 0.00047437504427757355 at epoch 348\n",
      "Error: 0.00047410085122007054 at epoch 349\n",
      "Error: 0.00047382773238423596 at epoch 350\n",
      "Error: 0.0004735556815271777 at epoch 351\n",
      "Error: 0.0004732846924504129 at epoch 352\n",
      "Error: 0.00047301475899952524 at epoch 353\n",
      "Error: 0.00047274587506380825 at epoch 354\n",
      "Error: 0.00047247803457592846 at epoch 355\n",
      "Error: 0.0004722112315115771 at epoch 356\n",
      "Error: 0.0004719454598891336 at epoch 357\n",
      "Error: 0.0004716807137693218 at epoch 358\n",
      "Error: 0.00047141698725488353 at epoch 359\n",
      "Error: 0.0004711542744902389 at epoch 360\n",
      "Error: 0.0004708925696611587 at epoch 361\n",
      "Error: 0.0004706318669944442 at epoch 362\n",
      "Error: 0.00047037216075758676 at epoch 363\n",
      "Error: 0.00047011344525846067 at epoch 364\n",
      "Error: 0.0004698557148449969 at epoch 365\n",
      "Error: 0.0004695989639048645 at epoch 366\n",
      "Error: 0.0004693431868651588 at epoch 367\n",
      "Error: 0.0004690883781920885 at epoch 368\n",
      "Error: 0.00046883453239066715 at epoch 369\n",
      "Error: 0.0004685816440044033 at epoch 370\n",
      "Error: 0.00046832970761499174 at epoch 371\n",
      "Error: 0.0004680787178420258 at epoch 372\n",
      "Error: 0.00046782866934268224 at epoch 373\n",
      "Error: 0.00046757955681142816 at epoch 374\n",
      "Error: 0.0004673313749797314 at epoch 375\n",
      "Error: 0.0004670841186157581 at epoch 376\n",
      "Error: 0.00046683778252409284 at epoch 377\n",
      "Error: 0.000466592361545443 at epoch 378\n",
      "Error: 0.000466347850556356 at epoch 379\n",
      "Error: 0.00046610424446893377 at epoch 380\n",
      "Error: 0.00046586153823055494 at epoch 381\n",
      "Error: 0.0004656197268235996 at epoch 382\n",
      "Error: 0.0004653788052651588 at epoch 383\n",
      "Error: 0.00046513876860677727 at epoch 384\n",
      "Error: 0.00046489961193417104 at epoch 385\n",
      "Error: 0.00046466133036696285 at epoch 386\n",
      "Error: 0.0004644239190584126 at epoch 387\n",
      "Error: 0.00046418737319514945 at epoch 388\n",
      "Error: 0.00046395168799691616 at epoch 389\n",
      "Error: 0.0004637168587163 at epoch 390\n",
      "Error: 0.0004634828806384824 at epoch 391\n",
      "Error: 0.0004632497490809755 at epoch 392\n",
      "Error: 0.000463017459393374 at epoch 393\n",
      "Error: 0.0004627860069570985 at epoch 394\n",
      "Error: 0.00046255538718514323 at epoch 395\n",
      "Error: 0.0004623255955218382 at epoch 396\n",
      "Error: 0.0004620966274425935 at epoch 397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.00046186847845365754 at epoch 398\n",
      "Error: 0.00046164114409187926 at epoch 399\n",
      "Error: 0.00046141461992446674 at epoch 400\n",
      "Error: 0.000461188901548745 at epoch 401\n",
      "Error: 0.00046096398459192806 at epoch 402\n",
      "Error: 0.00046073986471087815 at epoch 403\n",
      "Error: 0.00046051653759187624 at epoch 404\n",
      "Error: 0.00046029399895039866 at epoch 405\n",
      "Error: 0.00046007224453087695 at epoch 406\n",
      "Error: 0.0004598512701064814 at epoch 407\n",
      "Error: 0.00045963107147889746 at epoch 408\n",
      "Error: 0.0004594116444780957 at epoch 409\n",
      "Error: 0.00045919298496211776 at epoch 410\n",
      "Error: 0.00045897508881685716 at epoch 411\n",
      "Error: 0.00045875795195584365 at epoch 412\n",
      "Error: 0.00045854157032002577 at epoch 413\n",
      "Error: 0.00045832593987755896 at epoch 414\n",
      "Error: 0.0004581110566235949 at epoch 415\n",
      "Error: 0.00045789691658007454 at epoch 416\n",
      "Error: 0.00045768351579551444 at epoch 417\n",
      "Error: 0.0004574708503448095 at epoch 418\n",
      "Error: 0.00045725891632902155 at epoch 419\n",
      "Error: 0.00045704770987518053 at epoch 420\n",
      "Error: 0.00045683722713608357 at epoch 421\n",
      "Error: 0.0004566274642900957 at epoch 422\n",
      "Error: 0.00045641841754095493 at epoch 423\n",
      "Error: 0.0004562100831175715 at epoch 424\n",
      "Error: 0.0004560024572738389 at epoch 425\n",
      "Error: 0.00045579553628844057 at epoch 426\n",
      "Error: 0.0004555893164646585 at epoch 427\n",
      "Error: 0.0004553837941301857 at epoch 428\n",
      "Error: 0.000455178965636936 at epoch 429\n",
      "Error: 0.0004549748273608642 at epoch 430\n",
      "Error: 0.0004547713757017717 at epoch 431\n",
      "Error: 0.000454568607083135 at epoch 432\n",
      "Error: 0.0004543665179519167 at epoch 433\n",
      "Error: 0.0004541651047783921 at epoch 434\n",
      "Error: 0.00045396436405596496 at epoch 435\n",
      "Error: 0.00045376429230099667 at epoch 436\n",
      "Error: 0.00045356488605262564 at epoch 437\n",
      "Error: 0.0004533661418725996 at epoch 438\n",
      "Error: 0.00045316805634510013 at epoch 439\n",
      "Error: 0.0004529706260765703 at epoch 440\n",
      "Error: 0.0004527738476955496 at epoch 441\n",
      "Error: 0.0004525777178525048 at epoch 442\n",
      "Error: 0.000452382233219663 at epoch 443\n",
      "Error: 0.0004521873904908465 at epoch 444\n",
      "Error: 0.00045199318638130674 at epoch 445\n",
      "Error: 0.00045179961762757134 at epoch 446\n",
      "Error: 0.00045160668098727293 at epoch 447\n",
      "Error: 0.0004514143732389938 at epoch 448\n",
      "Error: 0.00045122269118210714 at epoch 449\n",
      "Error: 0.0004510316316366244 at epoch 450\n",
      "Error: 0.0004508411914430337 at epoch 451\n",
      "Error: 0.0004506513674621471 at epoch 452\n",
      "Error: 0.0004504621565749523 at epoch 453\n",
      "Error: 0.000450273555682454 at epoch 454\n",
      "Error: 0.00045008556170553346 at epoch 455\n",
      "Error: 0.0004498981715847869 at epoch 456\n",
      "Error: 0.0004497113822803864 at epoch 457\n",
      "Error: 0.0004495251907719312 at epoch 458\n",
      "Error: 0.00044933959405830617 at epoch 459\n",
      "Error: 0.00044915458915752583 at epoch 460\n",
      "Error: 0.0004489701731066088 at epoch 461\n",
      "Error: 0.0004487863429614185 at epoch 462\n",
      "Error: 0.00044860309579653715 at epoch 463\n",
      "Error: 0.0004484204287051162 at epoch 464\n",
      "Error: 0.00044823833879874486 at epoch 465\n",
      "Error: 0.00044805682320730967 at epoch 466\n",
      "Error: 0.0004478758790788584 at epoch 467\n",
      "Error: 0.0004476955035794685 at epoch 468\n",
      "Error: 0.0004475156938931094 at epoch 469\n",
      "Error: 0.00044733644722151075 at epoch 470\n",
      "Error: 0.000447157760784035 at epoch 471\n",
      "Error: 0.00044697963181754426 at epoch 472\n",
      "Error: 0.000446802057576267 at epoch 473\n",
      "Error: 0.0004466250353316781 at epoch 474\n",
      "Error: 0.00044644856237236727 at epoch 475\n",
      "Error: 0.0004462726360039089 at epoch 476\n",
      "Error: 0.0004460972535487486 at epoch 477\n",
      "Error: 0.00044592241234606313 at epoch 478\n",
      "Error: 0.00044574810975165616 at epoch 479\n",
      "Error: 0.000445574343137819 at epoch 480\n",
      "Error: 0.00044540110989322077 at epoch 481\n",
      "Error: 0.00044522840742278424 at epoch 482\n",
      "Error: 0.000445056233147569 at epoch 483\n",
      "Error: 0.0004448845845046484 at epoch 484\n",
      "Error: 0.00044471345894700096 at epoch 485\n",
      "Error: 0.00044454285394338755 at epoch 486\n",
      "Error: 0.0004443727669782364 at epoch 487\n",
      "Error: 0.00044420319555153466 at epoch 488\n",
      "Error: 0.00044403413717871104 at epoch 489\n",
      "Error: 0.0004438655893905203 at epoch 490\n",
      "Error: 0.0004436975497329413 at epoch 491\n",
      "Error: 0.0004435300157670583 at epoch 492\n",
      "Error: 0.00044336298506895456 at epoch 493\n",
      "Error: 0.00044319645522960296 at epoch 494\n",
      "Error: 0.00044303042385476023 at epoch 495\n",
      "Error: 0.0004428648885648546 at epoch 496\n",
      "Error: 0.00044269984699489025 at epoch 497\n",
      "Error: 0.0004425352967943293 at epoch 498\n",
      "Error: 0.00044237123562700006 at epoch 499\n",
      "Our network believes that 0.1 + 0.2 is equal to 0.28395839541776563\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# create a dataset to train a network for the sum operation\n",
    "items = np.array([[random.random() / 2 for _ in range(2)] for _ in range(1000)])\n",
    "targets = np.array([[i[0] + i[1]] for i in items])\n",
    "\n",
    "# create an mlp\n",
    "mlp2 = MLP(2, [5], 1)\n",
    "\n",
    "# train our mlp\n",
    "mlp2.train(items, targets, 500, 0.05, True)\n",
    "\n",
    "# create dummy data\n",
    "inp_test = np.array([.1, .2])\n",
    "tar_test = np.array([.3])\n",
    "\n",
    "output_test = mlp2.forward_propagate(inp_test)\n",
    "print(\"Our network believes that {} + {} is equal to {}\".format(inp_test[0], inp_test[1], output_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ad7716",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
