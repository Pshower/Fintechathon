{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0635c98",
   "metadata": {},
   "source": [
    "# 4 GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "141bd031",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "def start_audio(time = 5,save_file=\"01_data_user/genium/test2.wav\"):\n",
    "    print(\"start recording!\")\n",
    "    \n",
    "#     CHUNK = 1024\n",
    "#     FORMAT = pyaudio.paInt16\n",
    "#     CHANNELS = 2\n",
    "#     RATE = 16000\n",
    "#     RECORD_SECONDS = time  #需要录制的时间\n",
    "#     WAVE_OUTPUT_FILENAME = save_file #保存的文件名\n",
    "#     p = pyaudio.PyAudio() #初始化\n",
    "    \n",
    "#     print(\"ON\")\n",
    "\n",
    "#     stream = p.open(format=FORMAT,\n",
    "#                     channels=CHANNELS,\n",
    "#                     rate=RATE,\n",
    "#                     input=True,\n",
    "#                     frames_per_buffer=CHUNK)#创建录音文件\n",
    "#     frames = []\n",
    "\n",
    "#     for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "#         data = stream.read(CHUNK)\n",
    "#         frames.append(data)#开始录音\n",
    "#     stream.stop_stream()\n",
    "#     stream.close()\n",
    "#     p.terminate()\n",
    "\n",
    "#     print(\"OFF\")\n",
    "    \n",
    "#     wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\t#保存\n",
    "#     wf.setnchannels(CHANNELS)\n",
    "#     wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "#     wf.setframerate(RATE)\n",
    "#     wf.writeframes(b''.join(frames))\n",
    "#     wf.close()\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44ae0000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "import os\n",
    "import librosa\n",
    "import math\n",
    "import json\n",
    "\n",
    "# DATASET_PATH = \"res/Data/genres_reduced\"\n",
    "DATASET_PATH = \"01_data_user\"\n",
    "# JSON_PATH = \"data.json\"\n",
    "JSON_PATH = \"data_add_user.json\"\n",
    "SAMPLE_RATE = 22050\n",
    "DURATION = 5 # measured in seconds\n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE * DURATION\n",
    "\n",
    "\n",
    "def save_mfcc(dataset_path, json_path, n_mfcc = 13, n_fft = 2048, hop_length = 512, num_segments = 5):\n",
    "    \n",
    "    # dictionary to store data\n",
    "#     data = {\n",
    "#         \"mapping\" : [\"classical\", \"blues\"],\n",
    "#         \"mfcc\" : [[], [], []],\n",
    "#         \"labels\" : [0, 0, 1]\n",
    "#     }\n",
    "    data = {\n",
    "        \"mapping\" : [],\n",
    "        \"mfcc\" : [],\n",
    "        \"labels\" : []\n",
    "    }\n",
    "    \n",
    "    num_samples_per_segments = int(SAMPLES_PER_TRACK / num_segments)\n",
    "    expected_num_mfcc_vectors_per_segment = math.ceil(num_samples_per_segments / hop_length) # 1.2 -> 2\n",
    "    \n",
    "    # loop through all the genres\n",
    "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
    "        \n",
    "        # ensure that we're not at the root level\n",
    "        if dirpath is not dataset_path:\n",
    "            \n",
    "            # save the semantic label\n",
    "            dirpath_components = dirpath.split(\"/\") # genre/blues => [\"genre\", \"blues\"]\n",
    "            semantic_label = dirpath_components[-1]\n",
    "            data[\"mapping\"].append(semantic_label)\n",
    "#             print(\"\\nProcessing {}\".format(semantic_label))\n",
    "            \n",
    "            # process files for a specific genre\n",
    "            for f in filenames:\n",
    "                \n",
    "                # load audio file\n",
    "                file_path = os.path.join(dirpath, f)\n",
    "                signal, sr = librosa.load(file_path, sr = SAMPLE_RATE)\n",
    "                \n",
    "                # process segments extracting mfcc and storing data\n",
    "                for s in range(num_segments):\n",
    "                    start_sample = num_samples_per_segments * s # s = 0 -> 0\n",
    "                    finish_sample = start_sample + num_samples_per_segments # s = 0 -> num_samples_per_segments\n",
    "                    \n",
    "                    mfcc = librosa.feature.mfcc(y = signal[start_sample:finish_sample],\n",
    "                                                sr = sr,\n",
    "                                                n_fft = n_fft,\n",
    "                                                n_mfcc = n_mfcc,\n",
    "                                                hop_length = hop_length\n",
    "                                                )\n",
    "                    \n",
    "                    mfcc = mfcc.T\n",
    "                    \n",
    "                    \n",
    "                    # store mfcc for segment if it has the expected length\n",
    "                    if len(mfcc) == expected_num_mfcc_vectors_per_segment:\n",
    "                        data[\"mfcc\"].append(mfcc.tolist())\n",
    "                        data[\"labels\"].append(i - 1) # first i is data_path itself\n",
    "#                         print(\"{}, segment: {}\".format(file_path, s))\n",
    "                    \n",
    "    with open(json_path, \"w\") as fp:\n",
    "        json.dump(data, fp, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b51afb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATA_PATH = \"data_add_user.json\"\n",
    "\n",
    "def load_data(data_path):\n",
    "    \"\"\"Loads training dataset from json file\n",
    "    \n",
    "        :param data_path (str): Path to json file containing data\n",
    "        :return X (ndarray): Inputs\n",
    "        :return y (ndarray): Targets\n",
    "    \n",
    "    \"\"\"\n",
    "    with open(data_path, \"r\") as fp:\n",
    "        data = json.load(fp)\n",
    "        \n",
    "    X = np.array(data[\"mfcc\"])\n",
    "    y = np.array(data[\"labels\"])\n",
    "    return X, y\n",
    "\n",
    "def prepare_datasets(test_size, validation_size):\n",
    "    \n",
    "    # load data\n",
    "    X, y = load_data(DATA_PATH)\n",
    "    \n",
    "    # create train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size)\n",
    "    \n",
    "    # create train/validation split\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size = validation_size)\n",
    "    \n",
    "    return (X_train, X_validation, X_test, y_train, y_validation, y_test)\n",
    "\n",
    "def build_model(input_shape):\n",
    "    \"\"\"\n",
    "    Generates RNN-LSTM model\n",
    "    \n",
    "    :param input_shape (tuple): Shape of input set\n",
    "    :return model: RNN-LSTM model\n",
    "    \"\"\"\n",
    "    \n",
    "    # create model\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # 3 LSTM layers\n",
    "    model.add(keras.layers.LSTM(512, input_shape = input_shape, return_sequences = True))\n",
    "    model.add(keras.layers.LSTM(256))\n",
    "    \n",
    "    # dense layers\n",
    "    model.add(keras.layers.Dense(128, activation = 'relu'))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    # dense layers\n",
    "    model.add(keras.layers.Dense(32, activation = 'relu'))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    \n",
    "    # output layer\n",
    "    model.add(keras.layers.Dense(2, activation = 'softmax'))\n",
    "    \n",
    "    return model\n",
    "    \n",
    "    \n",
    "def plot_history(history):\n",
    "    \n",
    "    fig, axs = plt.subplots(2)\n",
    "    plt.figure(dpi=450)\n",
    "    # create accuracy subplot\n",
    "    axs[0].plot(history.history[\"accuracy\"], label = \"train accuracy\")\n",
    "    axs[0].plot(history.history[\"val_accuracy\"], label = \"test accuracy\")\n",
    "    axs[0].set_ylabel(\"Accuracy\")\n",
    "    axs[0].legend(loc = \"lower right\")\n",
    "    axs[0].set_title(\"Accuracy eval\")\n",
    "    \n",
    "    # create accuracy subplot\n",
    "    axs[1].plot(history.history[\"loss\"], label = \"train error\")\n",
    "    axs[1].plot(history.history[\"val_loss\"], label = \"test error\")\n",
    "    axs[1].set_ylabel(\"Error\")\n",
    "    axs[1].set_xlabel(\"Epoch\")\n",
    "    axs[1].legend(loc = \"upper right\")\n",
    "    axs[1].set_title(\"Error eval\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def predict(model, X, y):\n",
    "    \n",
    "    X = X[np.newaxis, ...]\n",
    "    \n",
    "    # prediction = [ [0.1, 0.2, ...]]\n",
    "    prediction = model.predict(X) # X -> (1, 130, 13, 1)\n",
    "    \n",
    "    # extract index with max value\n",
    "    predicted_index = np.argmax(prediction, axis = 1) #[4]\n",
    "    print(\"Expected index: {}, Predicted index: {}\".format(y,  predicted_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "972ab8ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pshower/miniconda3/envs/Fintech/lib/python3.9/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=0\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a real human!\n"
     ]
    }
   ],
   "source": [
    "# print(\"start detecting!\")\n",
    "save_mfcc(DATASET_PATH, JSON_PATH)\n",
    "model=keras.models.load_model('02_model/1205_5s.h5')\n",
    "# load data\n",
    "X, y = load_data(DATA_PATH)\n",
    "y_pre_prob = model.predict(X)\n",
    "y_pre = np.argmax(y_pre_prob, axis = 1)\n",
    "y_pre_c = [0 if x > y - 0.9999999 else 1 for x, y in y_pre_prob]\n",
    "\n",
    "if(all(y_pre_id == 1 for y_pre_id in y_pre_c)):\n",
    "    print(\"You are a real human!\")\n",
    "\n",
    "else:\n",
    "    print(\"You're probably a robot!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a90e6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcefea96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e2f00f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.781276e-10, 1.000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78f4e4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre_c = [0 if x > y - 0.9999999 else 1 for x, y in y_pre_prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a38bd00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 1, 0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bde201a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39ea4ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.7004186e-13, 1.0000000e+00],\n",
       "       [2.3388203e-13, 1.0000000e+00],\n",
       "       [4.8844693e-09, 1.0000000e+00],\n",
       "       [2.4617463e-04, 9.9975377e-01],\n",
       "       [1.5485071e-09, 1.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f310d33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_audio():\n",
    "    print(\"start detecting!\")\n",
    "    save_mfcc(DATASET_PATH, JSON_PATH)\n",
    "    model=keras.models.load_model('02_model/1205_5s.h5')\n",
    "    # load data\n",
    "    X, y = load_data(DATA_PATH)\n",
    "    y_pre_prob = model.predict(X)\n",
    "    y_pre = np.argmax(y_pre_prob, axis = 1)\n",
    "    \n",
    "    if(all(y_pre_id == 1 for y_pre_id in y_pre)):\n",
    "        print(\"You are a real human!\")\n",
    "        \n",
    "    else:\n",
    "        print(\"You're probably a robot!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b552a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 10:51:15.876106: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-07 10:51:15.896242: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-07 10:51:15.896823: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-07 10:51:15.897827: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-07 10:51:15.900078: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-07 10:51:15.900704: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-07 10:51:15.901168: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-07 10:51:16.596840: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-07 10:51:16.597575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-07 10:51:16.597594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1609] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-12-07 10:51:16.597957: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-07 10:51:16.598022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1613 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-12-07 10:51:18.601165: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8101\n",
      "2024-12-07 10:51:19.769663: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "import sys\n",
    "\n",
    "class ExampleApp(tk.Tk):\n",
    "    def __init__(self):\n",
    "        super(ExampleApp, self).__init__()\n",
    "        self.title(\"Vioce Detect\")\n",
    "        \n",
    "        toolBar = tk.Frame(self)\n",
    "        toolBar.pack(side=tk.TOP, fill=tk.X)\n",
    "\n",
    "        button1 = tk.Button(self, text='Record', command=self.rec)\n",
    "        button2 = tk.Button(self, text='Detect', command=self.det)\n",
    "        button1.pack(in_=toolBar, side=tk.LEFT)\n",
    "        button2.pack(in_=toolBar, side=tk.LEFT)\n",
    "\n",
    "        self.text = tk.Text(self, wrap='word')\n",
    "        self.text.pack(side=tk.TOP, fill=tk.BOTH, expand=True)\n",
    "        self.text.tag_configure('stderr', foreground='#b22222')\n",
    "\n",
    "        sys.stdout = TextRedirector(self.text, 'stdout')\n",
    "        sys.stderr = TextRedirector(self.text, 'stderr')\n",
    "\n",
    "    def rec(self):\n",
    "        start_audio()\n",
    "\n",
    "    def det(self):\n",
    "        detect_audio()\n",
    "\n",
    "class TextRedirector(object):\n",
    "    def __init__(self, widget, tag='stdout'):\n",
    "        self.widget = widget\n",
    "        self.tag = tag\n",
    "\n",
    "    def write(self, str):\n",
    "        self.widget.configure(state='normal')\n",
    "        self.widget.insert(tk.END, str, (self.tag,))    # (self.tag,) 是设置配置\n",
    "        self.widget.configure(state='disabled')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app = ExampleApp()\n",
    "    app.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad417bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "import sys\n",
    "\n",
    "class ExampleApp(tk.Tk):\n",
    "    def __init__(self):\n",
    "        super(ExampleApp, self).__init__()\n",
    "        self.title(\"Voice Detect\")\n",
    "        \n",
    "        # 创建工具栏框架，并使用Grid布局\n",
    "        toolBar = tk.Frame(self)\n",
    "        toolBar.pack(side=tk.TOP, fill=tk.X)\n",
    "        \n",
    "        # 创建按钮并添加到工具栏\n",
    "        button1 = tk.Button(toolBar, text='Record', command=self.rec, padx=10, pady=5)\n",
    "        button2 = tk.Button(toolBar, text='Detect', command=self.det, padx=10, pady=5)\n",
    "        button1.grid(row=0, column=0, padx=10, pady=5)\n",
    "        button2.grid(row=0, column=1, padx=10, pady=5)\n",
    "\n",
    "        # 创建滚动条和文本框\n",
    "        self.scrollbar = tk.Scrollbar(self)\n",
    "        self.scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "        \n",
    "        self.text = tk.Text(self, wrap='word', yscrollcommand=self.scrollbar.set)\n",
    "        self.text.pack(side=tk.TOP, fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        self.scrollbar.config(command=self.text.yview)\n",
    "        \n",
    "        self.text.tag_configure('stderr', foreground='#b22222')\n",
    "\n",
    "        sys.stdout = TextRedirector(self.text, 'stdout')\n",
    "        sys.stderr = TextRedirector(self.text, 'stderr')\n",
    "\n",
    "    def rec(self):\n",
    "        try:\n",
    "            start_audio()\n",
    "        except Exception as e:\n",
    "            sys.stderr.write(f\"Error starting audio: {e}\\n\")\n",
    "\n",
    "    def det(self):\n",
    "        try:\n",
    "            detect_audio()\n",
    "        except Exception as e:\n",
    "            sys.stderr.write(f\"Error detecting audio: {e}\\n\")\n",
    "\n",
    "class TextRedirector(object):\n",
    "    def __init__(self, widget, tag='stdout'):\n",
    "        self.widget = widget\n",
    "        self.tag = tag\n",
    "\n",
    "    def write(self, str):\n",
    "        self.widget.configure(state='normal')\n",
    "        self.widget.insert(tk.END, str, (self.tag,))\n",
    "        self.widget.configure(state='disabled')\n",
    "        self.widget.see(tk.END)  # 自动滚动到文本框的底部\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app = ExampleApp()\n",
    "    app.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3962e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa10b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the main window\n",
    "root = tk.Tk()\n",
    "root.title(\"Vioce Detect\")\n",
    " \n",
    "# Create a label widget\n",
    "label = tk.Label(root, text=\"I can detect whether you are a robot!\")\n",
    "\n",
    " \n",
    "# # 创建Tkinter窗口\n",
    "# window = tk.Tk()\n",
    " \n",
    "\n",
    "# # 创建文本框用于显示输出\n",
    "# output_text = tk.Text(window)\n",
    "# output_text.pack()\n",
    " \n",
    "# # 重定向标准输出到文本框\n",
    "# redirect_stdout_to_tkinter(output_text)\n",
    " \n",
    "# Pack the label into the main window\n",
    "label.pack(pady=10)\n",
    " \n",
    "# Create a record\n",
    "button = tk.Button(root, text=\"Record your voice\", command=start_audio)\n",
    " \n",
    "# Pack the button into the main window\n",
    "button.pack(pady=10)\n",
    "\n",
    "# Create a button widget\n",
    "button = tk.Button(root, text=\"Result\", command=detect_audio)\n",
    " \n",
    "# Pack the button into the main window\n",
    "button.pack(pady=10)\n",
    " \n",
    "# Start the Tkinter event loop\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de50d846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "\n",
    "# 创建主窗口\n",
    "root = tk.Tk()\n",
    "root.title('演示窗口')\n",
    "root.geometry('300x100+630+80')\n",
    "\n",
    "# 创建按钮\n",
    "btn1 = tk.Button(root, text=\"点击\")\n",
    "btn1.pack()\n",
    "\n",
    "# 定义点击事件\n",
    "def test(e):\n",
    "    messagebox.showinfo(\"窗口名称\", \"点击成功\")\n",
    "\n",
    "# 绑定事件\n",
    "btn1.bind(\"<Button-1>\", test)\n",
    "\n",
    "# 进入消息循环\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e25a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
