{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70ae1b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting pyqt5\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/b4/8c/4065950f9d013c4b2e588fe33cf04e564c2322842d84dbcbce5ba1dc28b0/PyQt5-5.15.11-cp38-abi3-manylinux_2_17_x86_64.whl (8.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting pyqt5-tools\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/11/7e/3a5bce0e31650e091a16826d7a588be8bd56c2ac30871286b6c90d68ceeb/pyqt5_tools-5.15.9.3.3-py3-none-any.whl (29 kB)\n",
      "Collecting PyQt5-sip<13,>=12.15 (from pyqt5)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/cb/2b/7081cfe59cc9777a9765e17df8ac3c6f86e542924f6db832cb1a72296af9/PyQt5_sip-12.16.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (268 kB)\n",
      "Collecting PyQt5-Qt5<5.16.0,>=5.15.2 (from pyqt5)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/95/70/1ba9b828387f42e0812b496ed637a950bf57a5d59b844d034841e8f9fb4f/PyQt5_Qt5-5.15.15-py3-none-manylinux2014_x86_64.whl (59.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.8/59.8 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click in /home/pshower/miniconda3/envs/Fintech/lib/python3.9/site-packages (from pyqt5-tools) (8.1.7)\n",
      "Collecting pyqt5\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/28/99/78db05e606dbb4a9425c159e7f1f64b69683c16ee3dcd0f97ed9ede6b205/PyQt5-5.15.9-cp37-abi3-manylinux_2_17_x86_64.whl (8.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyqt5-plugins<5.15.9.3,>=5.15.9.2.2 (from pyqt5-tools)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/3c/27/991247ea590ce8d95ef25d24a1b97d18db2192caf330401c6ac54983dd58/pyqt5_plugins-5.15.9.2.3-cp39-cp39-manylinux2014_x86_64.whl (68 kB)\n",
      "Collecting python-dotenv (from pyqt5-tools)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/6a/3e/b68c118422ec867fa7ab88444e1274aa40681c606d59ac27de5a5588f082/python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Collecting PyQt5-Qt5>=5.15.2 (from pyqt5)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/83/d4/241a6a518d0bcf0a9fcdcbad5edfed18d43e884317eab8d5230a2b27e206/PyQt5_Qt5-5.15.2-py3-none-manylinux2014_x86_64.whl (59.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting qt5-tools<5.15.2.2,>=5.15.2.1.2 (from pyqt5-plugins<5.15.9.3,>=5.15.9.2.2->pyqt5-tools)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/e2/45/3062d0df2bbc88ee4ea04b1073072b337b9e287c0b4ac12109729b413e2e/qt5_tools-5.15.2.1.3-py3-none-any.whl (13 kB)\n",
      "Collecting qt5-applications<5.15.2.3,>=5.15.2.2.2 (from qt5-tools<5.15.2.2,>=5.15.2.1.2->pyqt5-plugins<5.15.9.3,>=5.15.9.2.2->pyqt5-tools)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/35/e3/f5ab9980d601e62a75bb4d5d01d2324cb0d2a414f36474e26a83de409548/qt5_applications-5.15.2.2.3-py3-none-manylinux_2_17_x86_64.whl (85.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Error parsing dependencies of omegaconf: .* suffix can only be used with `==` or `!=` operators\n",
      "    PyYAML (>=5.1.*)\n",
      "            ~~~~~~^\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: PyQt5-Qt5, qt5-applications, python-dotenv, PyQt5-sip, qt5-tools, pyqt5, pyqt5-plugins, pyqt5-tools\n",
      "Successfully installed PyQt5-Qt5-5.15.2 PyQt5-sip-12.16.0 pyqt5-5.15.9 pyqt5-plugins-5.15.9.2.3 pyqt5-tools-5.15.9.3.3 python-dotenv-1.0.1 qt5-applications-5.15.2.2.3 qt5-tools-5.15.2.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install pyqt5 pyqt5-tools -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20063245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyQt5\n",
      "  Downloading PyQt5-5.15.11-cp38-abi3-manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting PyQt5-sip<13,>=12.15 (from PyQt5)\n",
      "  Downloading PyQt5_sip-12.16.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (421 bytes)\n",
      "Collecting PyQt5-Qt5<5.16.0,>=5.15.2 (from PyQt5)\n",
      "  Downloading PyQt5_Qt5-5.15.15-py3-none-manylinux2014_x86_64.whl.metadata (536 bytes)\n",
      "Downloading PyQt5-5.15.11-cp38-abi3-manylinux_2_17_x86_64.whl (8.2 MB)\n",
      "\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.8/8.2 MB\u001b[0m \u001b[31m17.6 kB/s\u001b[0m eta \u001b[36m0:07:00\u001b[0m^C\n",
      "\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.8/8.2 MB\u001b[0m \u001b[31m17.6 kB/s\u001b[0m eta \u001b[36m0:07:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install PyQt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afe1cf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import os\n",
    "import librosa\n",
    "import math\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "# from PyQt5.QtWidgets import QApplication, QMainWindow, QTextEdit, QPushButton, QVBoxLayout, QWidget, QFileDialog\n",
    "# from PyQt5.QtMultimedia import QMediaPlayer, QMediaContent\n",
    "# from PyQt5.QtCore import QUrl\n",
    "from PyQt5.QtWidgets import QApplication, QMainWindow, QTextEdit, QPushButton, QVBoxLayout, QHBoxLayout, QWidget, QFileDialog, QGridLayout\n",
    "from PyQt5.QtCore import Qt\n",
    "from PyQt5.QtMultimedia import QMediaContent, QMediaPlayer\n",
    "from PyQt5.QtGui import QFont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcc34960",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2091/2148190763.py:53: DeprecationWarning: sipPyTypeDict() is deprecated, the extension module should use sipPyTypeDictRef() instead\n",
      "  class MainWindow(QMainWindow):\n"
     ]
    }
   ],
   "source": [
    "# class MainWindow(QMainWindow):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.save_file = \"01_data_user/genuine/test.wav\" # 录音文件存储路径，或者加载的音频文件路径\n",
    "#         self.dataset_path = \"01_data_user\" \n",
    "#         self.json_path = \"data_add_user.json\" # 音频文件预处理，输出到的json文件路径\n",
    "#         self.model_path = '02_model/1205_5s.h5' # 训练好的模型文件路径\n",
    "#         self.initUI()\n",
    "#         self.show()\n",
    "\n",
    "#     def initUI(self):\n",
    "#         # 设置窗口标题和初始大小\n",
    "#         self.setWindowTitle('真人语音/合成音频检测')\n",
    "#         self.setGeometry(100, 100, 400, 600) # \n",
    "\n",
    "#         # 创建文本编辑控件\n",
    "#         self.text_edit = QTextEdit()\n",
    "#         self.text_edit.setPlainText('start')  # 初始时向文本控件中插入'start'语句\n",
    "\n",
    "#         # 创建按钮\n",
    "#         self.button1 = QPushButton('录音')\n",
    "#         self.button3 = QPushButton('加载音频文件')\n",
    "#         self.button4 = QPushButton('播放音频')\n",
    "#         self.button2 = QPushButton('检测')\n",
    "        \n",
    "#         # 将按钮和文本编辑控件添加到布局中\n",
    "        \n",
    "        \n",
    "#         layout = QVBoxLayout(self)\n",
    "#         layout.setSpacing(5)\n",
    "#         layout.addWidget(self.text_edit, 0, 0, 5, 1)\n",
    "#         layout.addWidget(self.button3, 1, 0)\n",
    "#         layout.addWidget(self.button1, 1, 1)\n",
    "#         layout.addWidget(self.button4, 2, 0)\n",
    "#         layout.addWidget(self.button2, 2, 1)\n",
    "\n",
    "#         # 创建一个中心小部件并设置布局\n",
    "#         central_widget = QWidget()\n",
    "#         central_widget.setLayout(layout)\n",
    "\n",
    "#         # 设置中心小部件\n",
    "#         self.setCentralWidget(central_widget)\n",
    "\n",
    "#         # 连接按钮的点击信号到槽函数\n",
    "#         self.button1.clicked.connect(self.on_button1_clicked)\n",
    "#         self.button2.clicked.connect(self.on_button2_clicked)\n",
    "#         self.button3.clicked.connect(self.on_button3_clicked)\n",
    "#         self.button4.clicked.connect(self.on_button4_clicked)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class MainWindow(QMainWindow):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.save_file = \"01_data_user/genuine/test.wav\"  # 录音文件存储路径，或者加载的音频文件路径\n",
    "        self.dataset_path = \"01_data_user\" \n",
    "        self.json_path = \"data_add_user.json\"  # 音频文件预处理，输出到的json文件路径\n",
    "        self.model_path = '02_model/1205_5s.h5'  # 训练好的模型文件路径\n",
    "        self.initUI()\n",
    "        self.show()\n",
    "\n",
    "    def initUI(self):\n",
    "        # 设置窗口标题和初始大小\n",
    "#         font = QFont('Arial', 20)\n",
    "        self.setWindowTitle('真人语音/合成音频检测')\n",
    "        self.setGeometry(100, 100, 600, 400) \n",
    "        self.setFont(QFont('Times', 15))\n",
    "\n",
    "        # 创建文本编辑控件\n",
    "        self.text_edit = QTextEdit()\n",
    "        self.text_edit.setPlainText('start')  # 初始时向文本控件中插入'start'语句\n",
    "        self.text_edit.setFont(QFont('Times', 20))\n",
    "\n",
    "        # 创建按钮\n",
    "        self.button1 = QPushButton('录音')\n",
    "        self.button1.setFont(QFont('Times', 15))\n",
    "        self.button3 = QPushButton('加载音频文件')\n",
    "        self.button3.setFont(QFont('Times', 15))\n",
    "        self.button4 = QPushButton('播放音频')\n",
    "        self.button4.setFont(QFont('Times', 15))\n",
    "        self.button2 = QPushButton('检测')\n",
    "        self.button2.setFont(QFont('Times', 15))\n",
    "        \n",
    "        # 创建一个垂直布局用于文本编辑控件\n",
    "        v_layout = QVBoxLayout()\n",
    "        v_layout.addWidget(self.text_edit)\n",
    "\n",
    "        # 创建一个水平布局用于按钮\n",
    "        h_layout = QGridLayout(self)\n",
    "        h_layout.addWidget(self.button3, 0, 0)\n",
    "        h_layout.addWidget(self.button1, 0, 1)\n",
    "        h_layout.addWidget(self.button4, 1, 0)\n",
    "        h_layout.addWidget(self.button2, 1, 1)\n",
    "\n",
    "        # 将水平和垂直布局添加到主布局中\n",
    "        main_layout = QVBoxLayout()\n",
    "        main_layout.addLayout(v_layout)\n",
    "        main_layout.addLayout(h_layout)\n",
    "\n",
    "        # 创建一个中心小部件并设置布局\n",
    "        central_widget = QWidget()\n",
    "        central_widget.setLayout(main_layout)\n",
    "\n",
    "        # 设置中心小部件\n",
    "        self.setCentralWidget(central_widget)\n",
    "\n",
    "        # 连接按钮的点击信号到槽函数\n",
    "        self.button1.clicked.connect(self.on_button1_clicked)\n",
    "        self.button2.clicked.connect(self.on_button2_clicked)\n",
    "        self.button3.clicked.connect(self.on_button3_clicked)\n",
    "        self.button4.clicked.connect(self.on_button4_clicked)\n",
    "        \n",
    "    def on_button1_clicked(self):\n",
    "        # 添加录音事件处理逻辑\n",
    "        self.text_edit.append('启动录音')\n",
    "        self.start_audio()\n",
    "        self.text_edit.append('录音完成')\n",
    "\n",
    "    def on_button2_clicked(self):\n",
    "        # 添加检测事件处理逻辑\n",
    "        self.text_edit.append('启动检测')\n",
    "#         res_str = self.detect_audio()\n",
    "        res_str = self.detect_audio_single()\n",
    "        self.text_edit.append('检测完成：\\n'+res_str)\n",
    "\n",
    "    def on_button3_clicked(self):\n",
    "        # 打开文件对话框并获取选择的文件路径\n",
    "        options = QFileDialog.Options()\n",
    "        options |= QFileDialog.DontUseNativeDialog\n",
    "        file_name, _ = QFileDialog.getOpenFileName(self, \"QFileDialog.getOpenFileName()\", \"\",\n",
    "                                                  \"All Files (*);;WAV Files (*.wav)\", options=options)\n",
    "        if file_name:\n",
    "            # print(f\"选择的文件路径: {file_name}\")\n",
    "            self.save_file = file_name\n",
    "            self.text_edit.append(\"Select file:\"+file_name)\n",
    "            \n",
    "    def on_button4_clicked(self):\n",
    "        # 播放音频\n",
    "        # 创建媒体播放器对象\n",
    "        self.mediaPlayer = QMediaPlayer(self)        \n",
    "        # 设置音频文件路径\n",
    "        url = QUrl.fromLocalFile(self.save_file)        \n",
    "        # 加载音频文件\n",
    "        self.mediaPlayer.setMedia(QMediaContent(url))\n",
    "        # 播放音频\n",
    "        self.mediaPlayer.play()\n",
    "\n",
    "    #######################################################################################\n",
    "    def start_audio(self, time = 5, save_file=\"01_data_user/genuine/test.wav\"):\n",
    "        CHUNK = 1024\n",
    "        FORMAT = pyaudio.paInt16\n",
    "        CHANNELS = 2\n",
    "        RATE = 16000\n",
    "        RECORD_SECONDS = time  #需要录制的时间\n",
    "        WAVE_OUTPUT_FILENAME = save_file #保存的文件名\n",
    "        p = pyaudio.PyAudio() #初始化\n",
    "\n",
    "        print(\"ON\")\n",
    "\n",
    "        stream = p.open(format=FORMAT,\n",
    "                        channels=CHANNELS,\n",
    "                        rate=RATE,\n",
    "                        input=True,\n",
    "                        frames_per_buffer=CHUNK)#创建录音文件\n",
    "        frames = []\n",
    "\n",
    "        for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "            data = stream.read(CHUNK)\n",
    "            frames.append(data)#开始录音\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        p.terminate()\n",
    "\n",
    "        print(\"OFF\")\n",
    "\n",
    "        wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\t#保存\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "        wf.setframerate(RATE)\n",
    "        wf.writeframes(b''.join(frames))\n",
    "        wf.close()\n",
    "    \n",
    "    def save_mfcc(self, dataset_path, json_path, n_mfcc = 13, n_fft = 2048, hop_length = 512, num_segments = 5):\n",
    "        SAMPLE_RATE = 22050\n",
    "        DURATION = 5 # measured in seconds\n",
    "        SAMPLES_PER_TRACK = SAMPLE_RATE * DURATION\n",
    "\n",
    "        data = {\n",
    "            \"mapping\" : [],\n",
    "            \"mfcc\" : [],\n",
    "            \"labels\" : []\n",
    "        }\n",
    "\n",
    "        num_samples_per_segments = int(SAMPLES_PER_TRACK / num_segments)\n",
    "        expected_num_mfcc_vectors_per_segment = math.ceil(num_samples_per_segments / hop_length) # 1.2 -> 2\n",
    "\n",
    "        # loop through all the genres\n",
    "        for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
    "\n",
    "            # ensure that we're not at the root level\n",
    "            if dirpath is not dataset_path:\n",
    "\n",
    "                # save the semantic label\n",
    "                dirpath_components = dirpath.split(\"/\") # genre/blues => [\"genre\", \"blues\"]\n",
    "                semantic_label = dirpath_components[-1]\n",
    "                data[\"mapping\"].append(semantic_label)\n",
    "   \n",
    "                for f in filenames:\n",
    "                    file_path = os.path.join(dirpath, f)\n",
    "                    signal, sr = librosa.load(file_path, sr = SAMPLE_RATE)\n",
    "                    for s in range(num_segments):\n",
    "                        start_sample = num_samples_per_segments * s # s = 0 -> 0\n",
    "                        finish_sample = start_sample + num_samples_per_segments # s = 0 -> num_samples_per_segments\n",
    "\n",
    "                        mfcc = librosa.feature.mfcc(y = signal[start_sample:finish_sample],\n",
    "                                                    sr = sr,\n",
    "                                                    n_fft = n_fft,\n",
    "                                                    n_mfcc = n_mfcc,\n",
    "                                                    hop_length = hop_length\n",
    "                                                    )\n",
    "                        mfcc = mfcc.T\n",
    "                        if len(mfcc) == expected_num_mfcc_vectors_per_segment:\n",
    "                            data[\"mfcc\"].append(mfcc.tolist())\n",
    "                            data[\"labels\"].append(i - 1) # first i is data_path itself\n",
    "        with open(json_path, \"w\") as fp:\n",
    "            json.dump(data, fp, indent = 4)\n",
    "    \n",
    "    \n",
    "    def save_mfcc_single(self, file_path, json_path, n_mfcc = 13, n_fft = 2048, hop_length = 512, num_segments = 5):\n",
    "        SAMPLE_RATE = 22050\n",
    "        DURATION = 5 # measured in seconds\n",
    "        SAMPLES_PER_TRACK = SAMPLE_RATE * DURATION\n",
    "        data = {\n",
    "            \"mapping\" : [],\n",
    "            \"mfcc\" : [],\n",
    "        }\n",
    "\n",
    "        num_samples_per_segments = int(SAMPLES_PER_TRACK / num_segments)\n",
    "        expected_num_mfcc_vectors_per_segment = math.ceil(num_samples_per_segments / hop_length) # 1.2 -> 2\n",
    "        \n",
    "        dirpath_components = file_path.split(\"/\") # genre/blues => [\"genre\", \"blues\"]\n",
    "        semantic_label = dirpath_components[-2]\n",
    "        data[\"mapping\"].append(semantic_label)\n",
    "   \n",
    "        print(\"file path is:\", file_path)\n",
    "        signal, sr = librosa.load(file_path, sr = SAMPLE_RATE)\n",
    "        for s in range(num_segments):\n",
    "            start_sample = num_samples_per_segments * s # s = 0 -> 0\n",
    "            finish_sample = start_sample + num_samples_per_segments # s = 0 -> num_samples_per_segments\n",
    "\n",
    "            mfcc = librosa.feature.mfcc(y = signal[start_sample:finish_sample],\n",
    "                                        sr = sr,\n",
    "                                        n_fft = n_fft,\n",
    "                                        n_mfcc = n_mfcc,\n",
    "                                        hop_length = hop_length\n",
    "                                        )\n",
    "            mfcc = mfcc.T\n",
    "            if len(mfcc) == expected_num_mfcc_vectors_per_segment:\n",
    "                data[\"mfcc\"].append(mfcc.tolist())\n",
    "        with open(json_path, \"w\") as fp:\n",
    "            json.dump(data, fp, indent = 4)\n",
    "            \n",
    "    ##################################################################################\n",
    "    def load_data(self, data_path):\n",
    "        \"\"\"Loads training dataset from json file\n",
    "\n",
    "            :param data_path (str): Path to json file containing data\n",
    "            :return X (ndarray): Inputs\n",
    "            :return y (ndarray): Targets\n",
    "\n",
    "        \"\"\"\n",
    "        with open(data_path, \"r\") as fp:\n",
    "            data = json.load(fp)\n",
    "\n",
    "        X = np.array(data[\"mfcc\"])\n",
    "        attr = 'labels'\n",
    "        if attr in data:\n",
    "            y = np.array(data[\"labels\"])\n",
    "        else:\n",
    "            y = None\n",
    "        return X, y\n",
    "    \n",
    "    def load_data_single(self, data_path):\n",
    "        \"\"\"Loads training dataset from json file\n",
    "\n",
    "            :param data_path (str): Path to json file containing data\n",
    "            :return X (ndarray): Inputs\n",
    "            :return y (ndarray): Targets\n",
    "\n",
    "        \"\"\"\n",
    "        with open(data_path, \"r\") as fp:\n",
    "            data = json.load(fp)\n",
    "\n",
    "        X = np.array(data[\"mfcc\"])\n",
    "        y = None\n",
    "        return X, y\n",
    "\n",
    "\n",
    "    def build_model(self, input_shape):\n",
    "        # create model\n",
    "        model = keras.Sequential()\n",
    "\n",
    "        # 3 LSTM layers\n",
    "        model.add(keras.layers.LSTM(512, input_shape = input_shape, return_sequences = True))\n",
    "        model.add(keras.layers.LSTM(256))\n",
    "\n",
    "        # dense layers\n",
    "        model.add(keras.layers.Dense(128, activation = 'relu'))\n",
    "        model.add(keras.layers.Dropout(0.3))\n",
    "        # dense layers\n",
    "        model.add(keras.layers.Dense(32, activation = 'relu'))\n",
    "        model.add(keras.layers.Dropout(0.3))\n",
    "\n",
    "        # output layer\n",
    "        model.add(keras.layers.Dense(2, activation = 'softmax'))\n",
    "\n",
    "        return model\n",
    "        \n",
    "    ###########################################################################################\n",
    "    def detect_audio_single(self):    \n",
    "        file_path = self.save_file\n",
    "        json_path = self.json_path\n",
    "        self.save_mfcc_single(file_path, json_path)\n",
    "        model=keras.models.load_model(self.model_path)\n",
    "        # load data\n",
    "        X, y = self.load_data_single(json_path)\n",
    "        y_pre_prob = model.predict(X)\n",
    "        y_pre = np.argmax(y_pre_prob, axis = 1)\n",
    "        if(all(y_pre_id == 1 for y_pre_id in y_pre)):\n",
    "            print(\"发音是真人!\")\n",
    "            return '发音是真人\\n'\n",
    "\n",
    "        else:\n",
    "            print(\"声音很可能是合成!\")\n",
    "            return \"声音很可能是合成!\\n\"\n",
    "        \n",
    "        \n",
    "    def detect_audio(self):    \n",
    "        DATASET_PATH = self.dataset_path\n",
    "        JSON_PATH = self.json_path\n",
    "        self.save_mfcc(DATASET_PATH, JSON_PATH)\n",
    "        model=keras.models.load_model(self.model_path)\n",
    "        # load data\n",
    "        X, y = self.load_data(JSON_PATH)\n",
    "        y_pre_prob = model.predict(X)\n",
    "        y_pre = np.argmax(y_pre_prob, axis = 1)\n",
    "        if(all(y_pre_id == 1 for y_pre_id in y_pre)):\n",
    "            print(\"发音是真人!\")\n",
    "            return '发音是真人\\n'\n",
    "\n",
    "        else:\n",
    "            print(\"声音很可能是合成!\")\n",
    "            return \"声音很可能是合成!\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bcb8867",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QLayout: Attempting to add QLayout \"\" to MainWindow \"\", which already has a layout\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pshower/miniconda3/envs/Fintech/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3558: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# 创建应用程序实例\n",
    "app = QApplication(sys.argv)\n",
    "window = MainWindow()\n",
    "window.show()\n",
    "# 运行应用程序\n",
    "sys.exit(app.exec_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191a28cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file = \"./01_data_user/genuine/test.wav\"\n",
    "\n",
    "# waveform\n",
    "signal, sr = librosa.load(file, sr=22050) # sr * T -> 22050 *30\n",
    "plt.figure(dpi=450)\n",
    "librosa.display.waveshow(signal, sr=sr)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb1b147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# fft -> spectrum\n",
    "fft = np.fft.fft(signal)\n",
    "\n",
    "magnitude = np.abs(fft)\n",
    "frequency = np.linspace(0, sr, len(magnitude))\n",
    "plt.figure(dpi=450)\n",
    "plt.plot(frequency, magnitude)\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"Magnitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1529b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_frequency = frequency[:int(len(frequency)/2)]\n",
    "left_magnitude = magnitude[:int(len(magnitude)/2)]\n",
    "plt.figure(dpi=450)\n",
    "plt.plot(left_frequency, left_magnitude)\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"Magnitude\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a1d83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stft -> spectrogram\n",
    "\n",
    "n_fft = 2048\n",
    "hop_length = 512\n",
    "\n",
    "stft = librosa.core.stft(signal, hop_length=hop_length, n_fft=n_fft)\n",
    "spectrogram = np.abs(stft)\n",
    "\n",
    "plt.figure(dpi=450)\n",
    "librosa.display.specshow(spectrogram, sr=sr, hop_length=hop_length)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe62497f",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_spectrogram = librosa.amplitude_to_db(spectrogram)\n",
    "plt.figure(dpi=450)\n",
    "librosa.display.specshow(log_spectrogram, sr=sr, hop_length=hop_length)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"log_Frequency\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e734b0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MFCCs\n",
    "MFCCs = librosa.feature.mfcc(y=signal, n_fft=n_fft, hop_length=hop_length, n_mfcc=13)\n",
    "plt.figure(dpi=450)\n",
    "librosa.display.specshow(MFCCs, sr=sr, hop_length=hop_length)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"MFCCs\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848fa90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PyQt5.QtWidgets import QApplication, QMainWindow\n",
    "from PyQt5.QtMultimedia import QMediaPlayer, QMediaContent\n",
    "from PyQt5.QtCore import QUrl\n",
    "\n",
    "class AudioPlayer(QMainWindow):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.setWindowTitle('PyQt5 Audio Player')\n",
    "        self.setGeometry(100, 100, 400, 300)\n",
    "        \n",
    "        # 创建媒体播放器对象\n",
    "        self.mediaPlayer = QMediaPlayer(self)\n",
    "        \n",
    "        # 设置音频文件路径\n",
    "        url = QUrl.fromLocalFile(\"your_audio_file.mp3\")\n",
    "        \n",
    "        # 加载音频文件\n",
    "        self.mediaPlayer.setMedia(QMediaContent(url))\n",
    "        \n",
    "        # 播放音频\n",
    "        self.mediaPlayer.play()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app = QApplication(sys.argv)\n",
    "    player = AudioPlayer()\n",
    "    player.show()\n",
    "    sys.exit(app.exec_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf04c8f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
